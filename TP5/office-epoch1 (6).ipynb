{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14458632,"sourceType":"datasetVersion","datasetId":9235073}],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport random\nimport math\nimport matplotlib.pyplot as plt\n\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", DEVICE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/office-script1/office_script_clean.txt\"\n\nwith open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n    text = f.read()\ntext = text[:1_500_000]\nprint(f\"using {len(text):,} chars\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chars = sorted(set(text))\nvocab_size = len(chars)\n\nstoi = {c:i for i,c in enumerate(chars)}\nitos = {i:c for i,c in enumerate(chars)}\n\ndef encode(s):\n    return [stoi[c] for c in s]\n\ndef decode(ids):\n    return \"\".join(itos[i] for i in ids)\n\nprint(\"vocab size:\", vocab_size)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEQ_LEN = 64\n\nsequences = []\nfor i in range(0, len(text) - SEQ_LEN, SEQ_LEN):\n    sequences.append(encode(text[i:i+SEQ_LEN+1]))\n\nprint(f\"got {len(sequences):,} sequences\")\n\nsplit = int(0.9 * len(sequences))\ntrain_seqs = sequences[:split]\nval_seqs   = sequences[split:]\n\nprint(f\"train: {len(train_seqs):,}, val: {len(val_seqs):,}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EMB = 64\nHID = 128\n\nclass CharLSTM(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, EMB)\n        self.lstm = nn.LSTM(EMB, HID, batch_first=True)\n        self.fc = nn.Linear(HID, vocab_size)\n\n    def forward(self, x):\n        x = self.embed(x)\n        out, _ = self.lstm(x)\n        return self.fc(out)\n\nmodel = CharLSTM().to(DEVICE)\nprint(f\"model: {EMB} -> {HID} -> {vocab_size}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.006)\ncriterion = nn.CrossEntropyLoss()\n\nEPOCHS = 150\nBATCH_SIZE = 24\n\nprint(f\"epochs: {EPOCHS}, batch: {BATCH_SIZE}, lr: 0.006\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hist = {\"tp\": [], \"vp\": []}\nprint(\"starting training\")\n\nfor epoch in range(EPOCHS):\n    warmup = 2\n    if epoch < warmup:\n        lr = 0.006 * (epoch + 1) / warmup\n    else:\n        p = (epoch - warmup) / (EPOCHS - warmup)\n        lr = 0.001 + (0.006 - 0.001) * 0.5 * (1 + math.cos(math.pi * p))\n\n    for g in optimizer.param_groups:\n        g[\"lr\"] = lr\n\n    random.shuffle(train_seqs)\n\n    \n    nbatches = len(train_seqs) // BATCH_SIZE\n    if nbatches == 0:\n        nbatches = 1\n\n    model.train()\n    total_loss = 0.0\n\n    for b in range(nbatches):\n        batch = train_seqs[b*BATCH_SIZE:(b+1)*BATCH_SIZE]\n        x = torch.tensor([s[:-1] for s in batch], device=DEVICE)\n        y = torch.tensor([s[1:]  for s in batch], device=DEVICE)\n\n        logits = model(x)\n        loss = criterion(logits.reshape(-1, vocab_size), y.reshape(-1))\n\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / nbatches\n    train_ppl = math.exp(min(avg_loss, 10))\n\n   \n    if epoch < 2 or epoch % 5 == 0 or epoch == EPOCHS - 1:\n        model.eval()\n        with torch.no_grad():\n            vl = 0.0\n            for s in val_seqs[:50]:\n                x = torch.tensor(s[:-1], device=DEVICE).unsqueeze(0)\n                y = torch.tensor(s[1:],  device=DEVICE).unsqueeze(0)\n                logits = model(x)\n                loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n                vl += loss.item()\n            vl /= 50\n            val_ppl = math.exp(min(vl, 10))\n    else:\n        val_ppl = hist[\"vp\"][-1]\n\n    hist[\"tp\"].append(train_ppl)\n    hist[\"vp\"].append(val_ppl)\n\n    print(f\"epoch {epoch+1}/{EPOCHS}: ppl={train_ppl:.2f}, val={val_ppl:.2f}, lr={lr:.4f}\")\n\nprint(f\"\\nbest val ppl: {min(hist['vp']):.2f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(hist[\"tp\"], label=\"train\")\nplt.plot(hist[\"vp\"], label=\"val\")\nplt.axhline(3.5, color=\"green\", linestyle=\"--\", label=\"target\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"perplexity\")\nplt.title(\"training\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate(seed_text, temp=0.7, steps=500):\n    model.eval()\n    seed = encode(seed_text)\n    h = None\n    x = torch.tensor(seed, device=DEVICE).unsqueeze(0)\n\n    with torch.no_grad():\n        for _ in range(steps):\n            emb = model.embed(x)\n            out, h = model.lstm(emb, h)\n            logits = model.fc(out[:, -1])\n            probs = F.softmax(logits / temp, dim=-1)\n            idx = torch.multinomial(probs, 1)\n            x = torch.cat([x, idx], dim=1)\n\n    return seed_text + decode(x[0].tolist()[len(seed):])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed = \"Michael: Hey Shaurya, get lost asap!\"\ntemps = [0.3, 0.7, 1.0]\n\nfor t in temps:\n    print(\"\\nTemperature:\", t)\n    print(\"-\" * 70)\n    print(generate(seed, temp=t)[:400])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}